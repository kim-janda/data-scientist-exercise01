{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8a67f8",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e33edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up needed library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#read in the csv data created in 00_LoadData.py\n",
    "# set the ? as NA values\n",
    "df = pd.read_csv(\"fullrecords.csv\", na_values = \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7996afb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'education_num', 'capital_gain', 'capital_loss',\n",
       "       'hours_week', 'over_50k', 'workclass', 'educlevel', 'maritalstatus',\n",
       "       'occup', 'race', 'sex', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the id columns that were used to join with the other tables\n",
    "df.drop(['workclass_id','education_level_id','marital_status_id','occupation_id',\n",
    "         'relationship_id','race_id','sex_id','country_id'], axis = 1, inplace = True)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee44f0",
   "metadata": {},
   "source": [
    "### Recodes/Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b993f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "age              0\n",
       "education_num    0\n",
       "capital_gain     0\n",
       "capital_loss     0\n",
       "hours_week       0\n",
       "over_50k         0\n",
       "workclass        0\n",
       "educlevel        0\n",
       "maritalstatus    0\n",
       "occup            0\n",
       "race             0\n",
       "sex              0\n",
       "country          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#based on the results of EDA we will need to impute the missing values and will go with the most frequent strategy\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy='most_frequent')\n",
    "\n",
    "imp_df = pd.DataFrame(imp.fit_transform(df), columns = df.columns, index = df.index)\n",
    "\n",
    "# check missing values after imputation\n",
    "imp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53df6f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priv     36705\n",
       "gov       6549\n",
       "self      5557\n",
       "nopay       21\n",
       "never       10\n",
       "Name: col_work, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hs          15784\n",
       "somecoll    14540\n",
       "bach         8025\n",
       "lths         6408\n",
       "grad         4085\n",
       "Name: col_educ, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "married        23044\n",
       "single         16117\n",
       "Div_sep_wid     9681\n",
       "Name: col_mar, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#implement some collapsing of educlevel, marital status, and workclass\n",
    "#set up the new mappings\n",
    "work = {\n",
    "    'State-gov' : 'gov', 'Federal-gov' : 'gov', 'Local-gov' : 'gov',\n",
    "    'Self-emp-not-inc' : 'self', 'Self-emp-inc' : 'self',\n",
    "    'Private' : 'priv',\n",
    "    'Without-pay' : 'nopay',\n",
    "    'Never-worked' : 'never'\n",
    "}\n",
    "educ = {\n",
    "    'Bachelors' : 'bach',\n",
    "    'HS-grad': 'hs',\n",
    "    '11th' : 'lths', '9th' : 'lths', '7th-8th': 'lths','5th-6th':'lths','10th':'lths','1st-4th':'lths','Preschool':'lths','12th':'lths',\n",
    "    'Masters' : 'grad', 'Doctorate':'grad','Prof-school':'grad',\n",
    "    'Some-college':'somecoll', 'Assoc-acdm':'somecoll','Assoc-voc':'somecoll'\n",
    "    \n",
    "}\n",
    "mar = {\n",
    "    'Never-married': 'single',\n",
    "    'Married-civ-spouse': 'married', 'Married-spouse-absent':'married','Married-AF-spouse':'married',\n",
    "    'Divorced': 'Div_sep_wid', 'Separated':'Div_sep_wid','Widowed':'Div_sep_wid'\n",
    "}\n",
    "\n",
    "#apply the mappings\n",
    "imp_df['col_work'] = imp_df['workclass'].replace(work)\n",
    "imp_df['col_educ'] = imp_df['educlevel'].replace(educ)\n",
    "imp_df['col_mar'] = imp_df['maritalstatus'].replace(mar)\n",
    "\n",
    "#check collapsings\n",
    "collist = ['col_work','col_educ','col_mar']\n",
    "for c in collist:\n",
    "    display(imp_df[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35bac1",
   "metadata": {},
   "source": [
    "### Create train/validation/test split (70/20/10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49702a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the target and predictor variables into X and Y\n",
    "# drop 'capital_gain','capital_loss', and 'country' based on EDA work\n",
    "X = imp_df[['id','age','education_num',\n",
    "       'hours_week', 'workclass', 'educlevel', 'maritalstatus',\n",
    "       'occup', 'race', 'sex', 'col_work', 'col_educ', 'col_mar']]\n",
    "y = imp_df[['id','over_50k']]\n",
    "\n",
    "# First split off 10 percent for the train data and 90 for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "#further split the test data to be 80 train and 20 validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=(.2/.9), random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c8328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  (34188, 13)\n",
      "Val. size:  (9769, 13)\n",
      "Test size:  (4885, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Train size: ', X_train.shape)\n",
    "print('Val. size: ', X_val.shape)\n",
    "print('Test size: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405c269",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646e6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
